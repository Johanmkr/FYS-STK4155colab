|                        | method   | optimiser   |   $n_\mathrm{obs}$ | #epochs   |   $m$ | $\eta$   |   $\lambda$ |   $\gamma$ | $\varrho_1$, $\varrho_2$   | $\theta_0$                            |   run time (s) | note                                                                     |
|:-----------------------|:---------|:------------|-------------------:|:----------|------:|:---------|------------:|-----------:|:---------------------------|:--------------------------------------|---------------:|:-------------------------------------------------------------------------|
| adagrad_GD.txt         | GD       | adagrad     |                400 | (25, 50)  |     1 | ...      |         0   |            |                            | [-0.59804832 -0.39324044  1.34226197] |              1 |                                                                          |
| adagrad_SGD.txt        | SGD      | adagrad     |                400 | (25, 50)  |    40 | ...      |         0   |            |                            | [-0.59804832 -0.39324044  1.34226197] |             32 |                                                                          |
| adam_GD.txt            | GD       | Adam        |                400 | (25, 50)  |     1 | ...      |         0   |            | (0.9, 0.999)               | [-0.59804832 -0.39324044  1.34226197] |              2 |                                                                          |
| adam_SGD.txt           | SGD      | Adam        |                400 | (25, 50)  |    40 | ...      |         0   |            | (0.9, 0.999)               | [-0.59804832 -0.39324044  1.34226197] |             26 |                                                                          |
| design_matrix.txt      |          |             |                400 |           |       |          |             |            |                            |                                       |                | $X = [x\, x^2\, x^3]$ (scaled)                                           |
| momentum_GD.txt        | GD       | momentum    |                400 | (25, 50)  |     1 | ...      |         0   |        0.5 |                            | [-0.59804832 -0.39324044  1.34226197] |              1 |                                                                          |
| momentum_SGD.txt       | SGD      | momentum    |                400 | (25, 50)  |    40 | ...      |         0   |        0.5 |                            | [-0.59804832 -0.39324044  1.34226197] |             38 |                                                                          |
| plain_GD.txt           | GD       | plain       |                400 | (25, 50)  |     1 | ...      |         0   |            |                            | [-0.59804832 -0.39324044  1.34226197] |              1 |                                                                          |
| plain_SGD.txt          | SGD      | plain       |                400 | (25, 50)  |    40 | ...      |         0   |            |                            | [-0.59804832 -0.39324044  1.34226197] |             35 |                                                                          |
| ridge_adagrad_SGD.txt  | SGD      | adagrad     |                400 | (25, 50)  |    40 | ...      |         0.1 |            |                            | [-0.59804832 -0.39324044  1.34226197] |             25 |                                                                          |
| ridge_adam_SGD.txt     | SGD      | Adam        |                400 | (25, 50)  |    40 | ...      |         0.1 |            | (0.9, 0.999)               | [-0.59804832 -0.39324044  1.34226197] |             42 |                                                                          |
| ridge_momentum_SGD.txt | SGD      | momentum    |                400 | (25, 50)  |    40 | ...      |         0.1 |        0.5 |                            | [-0.59804832 -0.39324044  1.34226197] |             32 |                                                                          |
| ridge_plain_SGD.txt    | SGD      | plain       |                400 | (25, 50)  |    40 | ...      |         0.1 |            |                            | [-0.59804832 -0.39324044  1.34226197] |             27 |                                                                          |
| ridge_rmsprop_SGD.txt  | SGD      | RMSprop     |                400 | (25, 50)  |    40 | ...      |         0.1 |            | 0.9                        | [-0.59804832 -0.39324044  1.34226197] |             35 |                                                                          |
| rmsprop_GD.txt         | GD       | RMSprop     |                400 | (25, 50)  |     1 | ...      |         0   |            | 0.9                        | [-0.59804832 -0.39324044  1.34226197] |              1 |                                                                          |
| rmsprop_SGD.txt        | SGD      | RMSprop     |                400 | (25, 50)  |    40 | ...      |         0   |            | 0.9                        | [-0.59804832 -0.39324044  1.34226197] |             32 |                                                                          |
| target_data.txt        |          |             |                400 |           |       |          |             |            |                            |                                       |                | $y  = 2.00 x + 1.70 x^2 + -0.40 x^3 \, + \, 0.10 \cdot N(0, 1)$ (scaled) |
| untitled.txt           | SGD      | adagrad     |                400 | (25, 50)  |     4 | ...      |         0   |            |                            | [-0.59804832 -0.39324044  1.34226197] |              5 |                                                                          |


# Results from simple regression analysis using (S)GD


## Additional information:

* $f(x) = 2.00 x + 1.70 x^2 + -0.40 x^3 \, + \, 0.10 \cdot N(0, 1)$
* Considered 11 logarithmically spaced learning rates $\eta \in [1.0e-05, \, 1.0e+00]$.
