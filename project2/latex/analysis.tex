\section{Analysis}\label{sec:analysis}

\comment{Present datasets}

$\datasetA = \big\{ (\vec{x}^{(1)}, y^{(1)}), \,  (\vec{x}^{(2)}, y^{(2)}), \,\dots, \, (\vec{x}^{({\npointsA})}, y^{(\npointsA)}) \big\}$ 

\comment{Maybe write something about the codes?}


OUTLINE:
\begin{enumerate}
    \item Gradient descent \begin{enumerate}
        \item[-] OLS and Ridge on regression problem
    \end{enumerate}
    \item Building our FFNN
    \item Regression problem \begin{enumerate}
        \item[-] try different activation functions
    \end{enumerate}
    \item Classification problem \begin{enumerate}
        \item[-] compare with logistic regression 
    \end{enumerate}
\end{enumerate}

\subsection{Gradient descent}

    We write a code that  \fillertext


    Using the SGD method, we perform an OLS regression on a dataset generated by a third order polynomial with some added noise,
    \begin{equation}
        f(x) = ax + bx^2 + cx^3 \, +\, d\mathcal{N}(0, 1). % fix numbers!
    \end{equation}
    In particular, we aim to minimise the cost function in eq. \eqref{eq:ols_cost_function} for which we need to tune the learning rate $\eta$. We perform the same analysis using the Ridge cost function in eq. \eqref{eq:ridge_cost_function}, but here we need to tune the penalty parameter $\lambda$ as well as the learning rate $\eta$. 

    We do not present many figures to describe this part of the analysis. We \rephrase{defend} this by arguing that the purpose of this part is to test the SGD code, and then by extension the GD code, and give an idea of the effect of changing optimisers. 

    In Figure \ref{fig:simple_reg_errors_ols}  \fillertext

    \begin{figure}
        \includegraphics[width=\linewidth]{errors_gradient_descent.pdf}
        \caption{This very cute figure is ...}
        \label{fig:simple_reg_errors_ols}
    \end{figure}

    \begin{figure}
        \includegraphics[width=\linewidth]{ridge_errors_gradient_descent.pdf}
        \caption{This very cute figure is \rephrase{unnecessary! Maybe remove? Or make subplot?} lambda is 0.1 i think}
        \label{fig:simple_reg_errors_ridge}
    \end{figure}




    
\subsection{Neural network}
    We will build our FFNN (\ref{item:build1}-\ref{item:build3}) and solve a supervised learning problem (\ref{item:solve1}-\ref{item:solve3}) using the steps listed below \citep{mhjensen}.

    \begin{enumerate}[label=(\roman*)]
        \item\label{item:build1} Collect and prepocess data, that is we extract 80\% of the dataset and reserve the rest for validation. The data is then scaled using Z-score \checkthis{CITE} normalisation with respect to the training data.
        \item\label{item:build2} Define the model and design its architecture. In practice, this means to decide on hyperparameters of the NN such as depth ($L$) and activation function(s) ($g$).
        \item\label{item:build3} Choose loss function and optimiser. For regression we will use the regular MSE score \checkthis{(ref!)} as the estimator of loss, whereas the classification problem estimates the loss according to the accuracy score \checkthis{(ref!)}. \wtf[please send help] The choice of optimiser is between GD and SGD, but includes decisions about the exact algorithm \rephrase{(how we optimise the learning rate)}.
        \item\label{item:solve1} Train the network to find the right weights and biases.
        \item\label{item:solve2} Validate model, i.e. assess model performance by applying it on the test data.
        \item\label{item:solve3} Adjust hyperparameters, and if necessary review the network architecture.
    \end{enumerate}

    

\subsection{Regression problem}\label{sec:analysis_regression}





\subsection{Classification problem}\label{sec:analysis_classification}

