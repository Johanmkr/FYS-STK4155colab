\section{Analysis}\label{sec:analysis}

\comment{Present datasets}

$\datasetA = \big\{ (\vec{x}^{(1)}, y^{(1)}), \,  (\vec{x}^{(2)}, y^{(2)}), \,\dots, \, (\vec{x}^{({\npointsA})}, y^{(\npointsA)}) \big\}$ 

\comment{Maybe write something about the codes?}

\subsection{Regression problem}\label{sec:analysis_regression}

    \subsubsection{Pre-NN}\label{sec:analysis_regressoin_preNN}
    \comment{Fix title}

    Using the \checkthis{GD/SGD} method, we perform an OLS regression on the dataset $\datasetA$ by using the cost function in eq. \eqref{eq:ols_cost_function}. We perform the same analysis using the Ridge cost function in eq. \eqref{eq:ridge_cost_function}, but here we need to tune the penalty parameter $\lambda$ as well as the learning rate $\eta$.




\subsection{Classification problem}\label{sec:analysis_classification}

