\section{Introduction}\label{sec:introduction}


Supervised learning problems dealing with regression and classification both benefit, or even rely on, optimisation methods for locating minima of some loss function. A commonly used solution in machine learning is the stochastic gradient descent algorithm with its many subvariants. We aim to investigate these subvariants in their right on an arbitrary testing polynomial. The result of this investigation will be paramount in the further development of a feedforward neural network that will be used both for linear and logistic regression problems, but also binary classification problems. It can also be extended to deal with multivariate classification problem, although this is not done here. 


Section \ref{sec:theory} presents the theoretical background of the following analysis in section \ref{sec:analysis}. Above lies the nomenclature of this paper, for reference. We summarise our results section \ref{sec:conclusion}. In more detail, in section \ref{sec:stochastic_gradient_descent} we describe the main ideas behind the methods of steepest descent. We move on to describe some basic theory concerning neural networks and the structure of a feedforward neural network in section \ref{sec:neural_network}. We connect this to linear regression in section \ref{sec:regression}, classification in \ref{sec:classification} and logistic regression in \ref{sec:logistic_regression}. In section \ref{sec:validation} we briefly state how models like these are validated in this paper. The analysis part is initiated with a simple regression problem in \ref{sec:analysis_SGD} concerning the steepest descent methods. We present how we build our neural network in \ref{sec:analysis_NN}, which we use to solve the more complex regression problem in section \ref{sec:analysis_regression}. We move on to a binary classification problem which we analyse with our neural network in section \ref{sec:analysis_classification} and with logistic regression in section \ref{sec:analysis_logistic_regression}. We present some closing thoughts in section \ref{sec:analysis_closing_words} before we summarise our main results in section \ref{sec:conclusion}.

There are three appendices to this report, \ref{app:regression}, \ref{app:classification} and \ref{app:logistic}, all of which support our analysis through a number of figures. Additional results can be found in the \href{\figureslink}{figure folder} on our Github repository, for the interested reader.